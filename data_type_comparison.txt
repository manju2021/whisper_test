import pandas as pd
import pyodbc

# Step 1: Connect to the SQL Server Database
connection_string = (
    "Driver={SQL Server Native Client 11.0};"
    "Server=sfskjsks\\S01;"  # Your server name with instance
    "Database=SPMREP_TEST;"
    "Trusted_Connection=yes;"
)
conn = pyodbc.connect(connection_string)

# Query to get SQL Server column data types
sql_query = """
SELECT COLUMN_NAME, DATA_TYPE
FROM INFORMATION_SCHEMA.COLUMNS
WHERE TABLE_NAME = 'your_table_name'
"""
sql_data = pd.read_sql(sql_query, conn)

# Step 2: Get the DataFrame column data types
# Example DataFrame
df = pd.DataFrame({
    'col1': [1, 2, 3],
    'col2': ['a', 'b', 'c'],
    'col3': [1.1, 2.2, 3.3]
})

# Get the data types from the DataFrame
df_dtypes = df.dtypes

# Step 3: Comparison
# Convert SQL data types to match Pandas types (simplified)
sql_to_pandas_types = {
    'int': 'int64',
    'varchar': 'object',  # Pandas stores strings as object dtype
    'nvarchar': 'object',
    'float': 'float64',
    'decimal': 'float64',
    'datetime': 'datetime64[ns]',
    'bit': 'bool'
}

# Create a dictionary for SQL data types
sql_data_types_dict = dict(zip(sql_data['COLUMN_NAME'], sql_data['DATA_TYPE']))

# Compare SQL data types with DataFrame data types
for col in df.columns:
    sql_type = sql_data_types_dict.get(col)
    pandas_type = str(df_dtypes[col])

    # Map the SQL type to the Pandas type
    mapped_sql_type = sql_to_pandas_types.get(sql_type.lower(), 'Unknown')

    print(f"Column: {col}")
    print(f"SQL Data Type: {sql_type}")
    print(f"Pandas Data Type: {pandas_type}")
    print(f"Mapped SQL to Pandas: {mapped_sql_type}")
    print("Match" if mapped_sql_type == pandas_type else "Mismatch")
    print("=" * 40)
